server=vllm
model_name=gpt-oss:20b

# This should match one of the keys in model_configs in model.conf
used_model=${server}"-"${model_name}

# The time in seconds to wait for the server to warm up.
server_warm_up_seconds=40

# The time in minutes that the server will wait before shutting down automatically.
server_idle_timeout_minutes=3

# The root directory where the vllm model weights are stored.
# The model folder structure should be like: /path/to/vllm_model_weights_root_dir/model_name
vllm_model_weights_root_dir=/workspace/commit-bot/exploration/

vllm_gpu_memory_utilization_limit=0.4
